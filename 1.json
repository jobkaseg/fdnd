[
  {
    "model": "gpt-4",
    "max_tokens": 3000,
    "description": "Default high-performance model for advanced use cases."
  },
  {
    "model": "gpt-3.5-turbo0000",
    "max_tokens": 2000,
    "description": "Optimized for speed and cost-effectiveness."
  },
  {
    "model": "gpt-3.5-turbo-16k0000",
    "max_tokens": 16000,
    "description": "Extended token limit for large context requirements."
  }

]
